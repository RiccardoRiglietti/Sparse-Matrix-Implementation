{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Definition of a sparse matrix"],"metadata":{"id":"ND2cwYzduzZS"}},{"cell_type":"markdown","source":["In numerical analysis and scientific computing, a sparse matrix or sparse array is a matrix in which most of the elements are zero. There is no strict definition regarding the proportion of zero-value elements for a matrix to qualify as sparse but a common criterion is that the number of non-zero elements is roughly equal to the number of rows or columns. By contrast, if most of the elements are non-zero, the matrix is considered dense. The number of zero-valued elements divided by the total number of elements (e.g., m × n for an m × n matrix) is sometimes referred to as the sparsity of the matrix. (From Wikipedia)"],"metadata":{"id":"g_tJTUt2FxbN"}},{"cell_type":"markdown","source":["# Applications of sparse matrices"],"metadata":{"id":"28B0ZPKL9XSQ"}},{"cell_type":"markdown","source":["Sparse matrices appear in the mathematical formulation of many problems, and when they do, having the correct way to represent them can be very useful to improve the efficiency of the computations:"],"metadata":{"id":"xa8VozG_GRFq"}},{"cell_type":"markdown","source":["## Pagerank"],"metadata":{"id":"F4qOYeC3JJ7g"}},{"cell_type":"markdown","source":["The world wide web can be represented as an adjency matrix M: if the page $i$ has a link going to the page $j$ the element $M_{ij}$ will be 1, otherwise it will be 0. This matrix is clearly extremely sparse, as the probability that a random webpage links to another random webpage is close to 0. Wikipedia has an excellent article describing how finding the \"pagerank\", that is, the relative importance of webpages, is analogous to finding the eigenvector with the highest eigenvalue, a problem that can be solved with repeated matrix vector multiplication (see last section of this notebook), this multiplication can be optimized if the matrix is sparse by using a correct data structure.\n","\n","This is a particularly important application of sparse matrices, as trying to store and utilize the whole matrix (including the zeros) would be impossible, given the size of World Wide Web. "],"metadata":{"id":"Hv_aTm02JODJ"}},{"cell_type":"markdown","source":["## SLAM"],"metadata":{"id":"zmKmCMS1JQL_"}},{"cell_type":"markdown","source":["SLAM (Simulataneous Location and Mapping), is a technique used in robotics and computer vision to estimate the pose (position and orientation) of a robot or a camera in an unknown environment, while at the same time creating a map of the environment. It is useful to build a Jacabian matrix, that contains the derivatives of all the observations with respect to all the state variables. In some cases, such as when the robot has many cameras, this matrix will be sparse, as moving camera number 4 will not change what camera number 1 sees. Knowing this, the algorithm can be optimized by representing the matrix with the correct data structure.\n","\n","This is also an important application of sparse matrices as optimizing this algorithm is very important as a SLAM algorithm should be fast enough to run in real time in order to be useful."],"metadata":{"id":"2AaEDCVcJTbr"}},{"cell_type":"markdown","source":["# Implementation of a sparse matrix data structure"],"metadata":{"id":"AS0mqFJSumCV"}},{"cell_type":"markdown","source":["I will now show the implementation of one of the simplest ways to represent a sparse matrix, the \"Dictionary of keys (DOK)\" data structure. It consists of a dictionary that maps (row, column)-pairs to the value of the elements. This representation is simple to construct, but not the most efficient when performing operations such as matrix-vector multiplication, but still, if the matrix is really large, even this simple data structure will show significant improvements over the standard dense matrix representation.\n","\n","The key idea is to completely ignore elements that are equal to zero, rather than waste time performing a huge number of multiplications by zero (that we already know will give zero as a result and not modify the final result).\n","\n","In fact the algorithmic time complexity of the multiplication of a dense matrix of size NxN by a vector of size N is O(N^3), if instead we use this data structure to represent an NxN matrix that has K non-zero elements, and multiply it by a vector fof size N, the algorithmic time complexity is O(KN), that is, while using a standard dense format to represent the matrix would waste time on the zeros, by using this data structure we only use time when we encounter a non-zero element, as the elements equal to 0 are not even saved in the data structure."],"metadata":{"id":"4tRnHYUTLJ6n"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"XZGr3X9ztKOu","executionInfo":{"status":"ok","timestamp":1671484124683,"user_tz":-60,"elapsed":217,"user":{"displayName":"riccardo riglietti","userId":"10238112883075356076"}}},"outputs":[],"source":["from re import X\n","from dataclasses import dataclass\n","from pprint import pprint\n","from collections import OrderedDict\n","import numpy as np\n","\n","\n","class SparseMatrix:\n","\n","    # Maybe it is better to have a dict {position: value}\n","    # or a dict of dicts {row_number: {column_number : value}}\n","    def __init__(self, items, dense_shape=None):\n","        # dictionary where \n","        self.items = items\n","        self.dense_shape = dense_shape\n","\n","    @staticmethod\n","    def from_dense(dense):\n","        new = SparseMatrix(OrderedDict(), dense.shape)\n","        for y, row in enumerate(dense):\n","            for x, item in enumerate(row):\n","                if item != 0:\n","                    new.items[(y, x)] = item\n","        return new\n","\n","    def multiply_by_vector(self, vector, verbose=False):\n","        res = np.zeros(vector.shape)\n","        for (y, x), matrix_item in self.items.items():\n","            vector_current_item = vector[x]\n","            res[y] += matrix_item * vector_current_item\n","            if verbose:\n","                pprint(locals())\n","        return res\n","\n","    def dense_representation(self):\n","        dense = np.zeros(self.dense_shape)\n","        for (y, x), item in self.items.items():\n","                dense[y][x] = item\n","        return dense\n","\n","    @staticmethod\n","    def random_sparse_matrix_dense_repr(size, sparsity=0.5):\n","        matrix = np.random.rand(size, size)\n","        for _ in range(int(sparsity * size * size)):\n","            x, y = np.random.randint(0, size, size=2)\n","            matrix[(y,x)] = 0.0\n","        return matrix\n","\n","    def __repr__(self):\n","        return f\"SparseMatrix({self.items})\"\n","\n","\n","    def __eq__(self, other):\n","        return self.items == other.items"]},{"cell_type":"markdown","source":["# Examples and tests"],"metadata":{"id":"MtoKy3RhutAI"}},{"cell_type":"code","source":["m = SparseMatrix.from_dense(np.array([\n","    [1, 2],\n","    [0, 3]\n","]))\n","\n","#print(m)\n","res = m.multiply_by_vector(np.array([1,2]), verbose=True)\n","#print(res)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOAcB7wZqMtT","outputId":"bac54c1f-aec5-403a-bc4f-47ced0ad7908","executionInfo":{"status":"ok","timestamp":1671484124973,"user_tz":-60,"elapsed":36,"user":{"displayName":"riccardo riglietti","userId":"10238112883075356076"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{'matrix_item': 1,\n"," 'res': array([1., 0.]),\n"," 'self': SparseMatrix(OrderedDict([((0, 0), 1), ((0, 1), 2), ((1, 1), 3)])),\n"," 'vector': array([1, 2]),\n"," 'vector_current_item': 1,\n"," 'verbose': True,\n"," 'x': 0,\n"," 'y': 0}\n","{'matrix_item': 2,\n"," 'res': array([5., 0.]),\n"," 'self': SparseMatrix(OrderedDict([((0, 0), 1), ((0, 1), 2), ((1, 1), 3)])),\n"," 'vector': array([1, 2]),\n"," 'vector_current_item': 2,\n"," 'verbose': True,\n"," 'x': 1,\n"," 'y': 0}\n","{'matrix_item': 3,\n"," 'res': array([5., 6.]),\n"," 'self': SparseMatrix(OrderedDict([((0, 0), 1), ((0, 1), 2), ((1, 1), 3)])),\n"," 'vector': array([1, 2]),\n"," 'vector_current_item': 2,\n"," 'verbose': True,\n"," 'x': 1,\n"," 'y': 1}\n"]}]},{"cell_type":"code","source":["SparseMatrix.random_sparse_matrix_dense_repr(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWsHNwJNoN86","outputId":"e8fcee81-be58-46c7-9669-6ddda4fe332a","executionInfo":{"status":"ok","timestamp":1671484124974,"user_tz":-60,"elapsed":27,"user":{"displayName":"riccardo riglietti","userId":"10238112883075356076"}}},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.79153357, 0.93667244, 0.76867383, 0.24554535, 0.29009017],\n","       [0.        , 0.        , 0.64663625, 0.        , 0.        ],\n","       [0.29323893, 0.37634697, 0.69547036, 0.48899589, 0.        ],\n","       [0.        , 0.        , 0.39943284, 0.53132024, 0.        ],\n","       [0.        , 0.69622971, 0.        , 0.93114841, 0.        ]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import numpy as np\n","\n","import unittest\n","\n","class TestSparseMatrix(unittest.TestCase):\n","\n","    def test_simple_conversion(self):\n","        matrix = np.array( [\n","            [1, 2, 3],\n","            [0, 0, 0],\n","            [0, 0, 1]\n","        ])\n","        sparse = SparseMatrix.from_dense(matrix)\n","        res = SparseMatrix(OrderedDict([\n","            ((0, 0), 1),\n","            ((0, 1), 2),\n","            ((0, 2), 3),\n","            ((2, 2), 1),\n","        ]))\n","        #print(sparse, res)\n","        self.assertEqual(sparse, res)\n","\n","    def test_simple_mult(self):\n","        matrix = np.array( [\n","            [1, 2, 3],\n","            [4, 0, 0],\n","            [0, 0, 1]\n","        ])\n","\n","        vector = np.array( [\n","            1,\n","            2,\n","            3\n","        ])\n","\n","        numpy_result = matrix @ vector\n","\n","        sparse_matrix = SparseMatrix.from_dense(matrix)\n","        res = np.array([1*1+2*2+3*3,\n","                        1*4,\n","                        3*1\n","                        ])\n","        sparse_res = sparse_matrix.multiply_by_vector(vector)\n","\n","        #print(locals())\n","        np.testing.assert_array_almost_equal(res, numpy_result) \n","        np.testing.assert_array_almost_equal(res, sparse_res) \n","\n","    def test_back_and_forth_is_equal_to_start(self):\n","        for _ in range(20):\n","            matrix = SparseMatrix.random_sparse_matrix_dense_repr(20)\n","            sparse = SparseMatrix.from_dense(matrix)\n","            dense_back = sparse.dense_representation()\n","            np.testing.assert_array_almost_equal(matrix, dense_back)\n","\n","    \n","    def test_multiplication_is_correct_oracle(self):\n","        for _ in range(20):\n","\n","            matrix = SparseMatrix.random_sparse_matrix_dense_repr(5)\n","            vector = np.random.rand(5)\n","\n","            numpy_result = matrix @ vector\n","\n","            sparse_matrix = SparseMatrix.from_dense(matrix)\n","            res = sparse_matrix.multiply_by_vector(vector)\n","\n","            #pprint(locals())\n","            np.testing.assert_array_almost_equal(res, numpy_result)\n","    \n","    \n","\n","unittest.main(verbosity=3, argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxDNGmfCwvvt","outputId":"cead5073-3272-4ac5-e5a2-158e28414c1c","executionInfo":{"status":"ok","timestamp":1671484125224,"user_tz":-60,"elapsed":266,"user":{"displayName":"riccardo riglietti","userId":"10238112883075356076"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["test_back_and_forth_is_equal_to_start (__main__.TestSparseMatrix) ... ok\n","test_multiplication_is_correct_oracle (__main__.TestSparseMatrix) ... ok\n","test_simple_conversion (__main__.TestSparseMatrix) ... ok\n","test_simple_mult (__main__.TestSparseMatrix) ... ok\n","\n","----------------------------------------------------------------------\n","Ran 4 tests in 0.092s\n","\n","OK\n"]},{"output_type":"execute_result","data":{"text/plain":["<unittest.main.TestProgram at 0x7ffb33c67760>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Finding eigenvectors with repeated multiplication"],"metadata":{"id":"hsh0_7bAuvv0"}},{"cell_type":"markdown","source":["When a vector is multiplied by a matrix that has at least one eigenvector, the component of the vector that is parallel to the eigenvector with the maximal eigenvalue (in module) is stretched by the eigenvalue of that eigenvector. The perpendicular components are modified in other ways, such as being rotated, deformed or stretched **less**. Iterating the alternation of this product and a normalization operation on the vector, all the other components of the vector perpendicular to the eigenvector with maximal eigenvalue will be removed and it will become equal to the eigenvector with the maximal eigenvalue. This is important for the PageRank algorithm, I suggest the excellent English Wikipedia article on PageRank for further reading."],"metadata":{"id":"iSDk_lrqMuvj"}},{"cell_type":"code","source":["matrix = np.random.rand(3,3)\n","v = np.random.rand(3)\n","\n","values, vectors = np.linalg.eig(matrix)\n","eig = vectors[:, 0]\n","\n","print(\"Note: an error of 2 is like an error of 0: the vectors just point in opposite directions (v_1 = -v_2)\")\n","\n","for _ in range(15):\n","    print(f\"Current estimate {v}, error from eigenvector {np.linalg.norm(v - eig)}\")\n","    r = matrix @ v\n","    v = r / np.linalg.norm(r)\n","\n","values, vectors = np.linalg.eig(matrix)\n","print(vectors[:, 0])"],"metadata":{"id":"rNhcZ7In07Oc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e14ffb9-b83e-4aff-bf61-139fec4758ac","executionInfo":{"status":"ok","timestamp":1671484125225,"user_tz":-60,"elapsed":12,"user":{"displayName":"riccardo riglietti","userId":"10238112883075356076"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Note: an error of 2 is like an error of 0: the vectors just point in opposite directions (v_1 = -v_2)\n","Current estimate [0.97841236 0.50677034 0.93098361], error from eigenvector 2.393000736292868\n","Current estimate [0.31257968 0.54548737 0.77764868], error from eigenvector 1.9992461461742412\n","Current estimate [0.33521081 0.48640987 0.80686997], error from eigenvector 1.9999446980688422\n","Current estimate [0.33091184 0.50277569 0.79856995], error from eigenvector 1.9999960511017525\n","Current estimate [0.33203959 0.49842065 0.80082867], error from eigenvector 1.999999719351945\n","Current estimate [0.33174038 0.49958294 0.80022822], error from eigenvector 1.9999999800507444\n","Current estimate [0.3318202  0.49927315 0.80038845], error from eigenvector 1.9999999985821337\n","Current estimate [0.33179892 0.49935575 0.80034575], error from eigenvector 1.9999999998992242\n","Current estimate [0.33180459 0.49933373 0.80035713], error from eigenvector 1.9999999999928373\n","Current estimate [0.33180308 0.4993396  0.8003541 ], error from eigenvector 1.9999999999994909\n","Current estimate [0.33180349 0.49933803 0.80035491], error from eigenvector 1.999999999999964\n","Current estimate [0.33180338 0.49933845 0.80035469], error from eigenvector 1.9999999999999973\n","Current estimate [0.33180341 0.49933834 0.80035475], error from eigenvector 1.9999999999999998\n","Current estimate [0.3318034  0.49933837 0.80035473], error from eigenvector 2.0\n","Current estimate [0.3318034  0.49933836 0.80035474], error from eigenvector 2.0\n","[-0.3318034  -0.49933836 -0.80035474]\n"]}]}]}
